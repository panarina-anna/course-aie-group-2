# HW06 – Report

> Файл: `homeworks/HW06/report.md`  

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (12000, 30)
- Целевая переменная: `target` (класс 0 - доля: 0.676583, класс 1 - доля: 0.323417)
- Признаки: 24 числовых непрерывных признака (num01–num24),
            3 категориально-подобных признака (cat_contract, cat_region, cat_payment),
            1 числовой признак tenure_months (121 уникальное значение),
            cтолбец id исключен из обучения.
.
## 2. Protocol

- Разбиение: train/test (75%/25% (9000/3000), `random_state` = 42, стратификация: по целевой переменной target)
- Подбор: CV на train (использован StratifiedKFold с 5 фолдами на train, оптимизация по ROC-AUC (scoring="roc_auc"))
- Метрики: Accuracy: общая доля правильных предсказаний,
           F1-score: гармоническое среднее precision и recall (важно при дисбалансе классов),
           ROC-AUC: площадь под ROC-кривой, оценивает способность модели разделять классы (при дисбалансе).

## 3. Models

Базовые модели:

1. DummyClassifier: стратегия "most_frequent" (всегда предсказывает самый частый класс)

2. LogisticRegression: с масштабированием через StandardScaler, подбор параметра регуляризации C из набора [0.01, 0.1, 0.3, 0.5, 1, 3, 5, 10, 15]

Модели недели 6:

1. DecisionTreeClassifier:

- max_depth: [None, 1-10]

- min_samples_leaf: [1, 5, 10, 15, 20, 25, 30, 35]

- ccp_alpha: [0.0, 0.00001, 0.001, 0.002, 0.005, 0.01]


2. RandomForestClassifier (300 деревьев):

- max_features: ["sqrt", 0.3, 0.5]

- min_samples_leaf: [1, 5, 10]

- max_depth: [None, 3, 5, 10, 20, 25]



3. HistGradientBoostingClassifier:

- learning_rate: [0.01, 0.03, 0.05, 0.1, 0.15]

- max_depth: [None, 1, 2, 3]

- max_leaf_nodes: [10, 15, 30, 40, 60, 75, 80]



Опционально:

1. StackingClassifier:

- Базовые модели: лучшие версии LR, DT, RF, HGB

- Мета-модель: LogisticRegression

- CV = 5

## 4. Results

- Список финальных метрик на test по всем моделям:

[{'accuracy': 0.6766666666666666,
 'f1': 0.0,
  'roc_auc': 0.5,
  'model': 'DummyClassifier(most_frequent)'},
 {'accuracy': 0.8296666666666667,
  'f1': 0.7146845337800112,
  'roc_auc': 0.878905083540704,
  'model': 'LogisticRegression'},
 {'accuracy': 0.866,
  'f1': 0.7927835051546391,
  'roc_auc': 0.9181803869788228,
  'model': 'DecisionTree'},
 {'accuracy': 0.9333333333333333,
  'f1': 0.8920086393088553,
  'roc_auc': 0.9701246762480322,
  'model': 'RandomForest'},
 {'accuracy': 0.939,
  'f1': 0.9024,
  'roc_auc': 0.9751297547102737,
  'model': 'HistGradientBoosting'},
 {'accuracy': 0.942,
  'f1': 0.9079365079365079,
  'roc_auc': 0.973569651109644,
  'model': 'Stacking'}]
  
- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение:

Победитель: HistGradientBoosting с ROC-AUC = 0.975130.

Хотя Stacking показал чуть лучшую accuracy (0.942000), HistGradientBoosting имеет наивысший ROC-AUC, что более важно при дисбалансе классов. Разница в ROC-AUC незначительна (0.975130 vs 0.973570), но HGB проще и быстрее.

## 5. Analysis

- Устойчивость:

Для проверки устойчивости было проведено 5 прогонов для RandomForest с разными random_state. Результаты ROC-AUC варьировались в диапазоне ±0.002, что указывает на хорошую устойчивость модели.

- Ошибки:

Модель хорошо предсказывает класс 0 (точность ≈ 97%)

С классом 1 есть больше ошибок (точность ≈ 87.2%)

Всего 183 ошибки из 3000 примеров (точность 93.9%)

- Интерпретация:

15 cамыx важныx признаков: num19, num18, num07, num04, num24, num14, num01, num20, num22, num06, num16, num21, num17, num08, num13. Категориально-подобные признаки не вошли в 15 наиболее важных признаков. Это получилось из-за того, что у категориально-подобных признаков небольшой диапазон значений, поэтому деревья могут сделать по ним мало разбиений и модель получает мало информации.
Непрерывные признаки дают больше возможностей для оптимизации.

## 6. Conclusion

- Ансамбли превосходят одиночные модели: RandomForest и HistGradientBoosting показали значительно лучшие результаты, чем LogisticRegression и DecisionTree по всем метрикам.

- Gradient Boosting эффективен при дисбалансе: HistGradientBoosting достиг наивысшего ROC-AUC (0.975).

- Stacking дает небольшое улучшение: Stacking немного улучшил accuracy, но проиграл в ROC-AUC и сложности реализации.

- Деревья контролируют переобучение: Для DecisionTree ключевыми были параметры max_depth, min_samples_leaf и ccp_alpha, что предотвратило переобучение.

- ROC-AUC - ключевая метрика при дисбалансе: При соотношении классов 68%/32% ROC-AUC лучше отражает качество модели, чем accuracy.

- Полный протокол важен для надежности: Использование стратификации, кросс-валидации и тестового набора обеспечивает воспроизводимость и надежность результатов.